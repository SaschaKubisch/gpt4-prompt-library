{
    "boundary_conditions": {
        "engine": {
            "value": "text-davinci-002",
            "description": "Specifies the AI model employed to generate predictions."
        },
        "max_tokens": {
            "value": 60,
            "description": "Specifies the maximum number of tokens that can be generated by the model."
        },
        "temperature": {
            "value": 0.7,
            "description": "Controls the randomness and creativity of the model’s predictions."
        },
        "top_p": {
            "value": 1.0,
            "description": "Specifies a sampling threshold during inference time."
        },
        "frequency_penalty": {
            "value": 0.0,
            "description": "Controls the model’s tendency to repeat predictions."
        },
        "presence_penalty": {
            "value": 0.0,
            "description": "Encourages the model to make novel predictions."
        }
    }
}
